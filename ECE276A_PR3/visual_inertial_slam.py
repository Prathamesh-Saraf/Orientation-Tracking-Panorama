# -*- coding: utf-8 -*-
"""Visual_Inertial_SLAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bCGSaON38KqQ5M3HTAU6bAlraRUjCK2K
"""

import numpy as np
import matplotlib.pyplot as plt
import transforms3d
from transforms3d.euler import mat2euler

def load_data(file_name):
    '''
    function to read visual features, IMU measurements, and calibration parameters
    Input:
        file_name: the input data file. Should look like "XX.npz"
    Output:
        t: time stamp
            with shape 1*t
        features: visual feature point coordinates in stereo images, 
            with shape 4*n*t, where n is number of features
        linear_velocity: velocity measurements in IMU frame
            with shape 3*t
        angular_velocity: angular velocity measurements in IMU frame
            with shape 3*t
        K: (left)camera intrinsic matrix
            with shape 3*3
        b: stereo camera baseline
            with shape 1
        imu_T_cam: extrinsic transformation from (left) camera to imu frame, in SE(3).
            with shape 4*4
    '''
    with np.load(file_name) as data:
    
        t = data["time_stamps"] # time_stamps
        features = data["features"] # 4 x num_features : pixel coordinates of the visual features
        linear_velocity = data["linear_velocity"] # linear velocity in body-frame coordinates
        angular_velocity = data["angular_velocity"] # angular velocity in body-frame coordinates
        K = data["K"] # intrinsic calibration matrix
        b = data["b"] # baseline
        imu_T_cam = data["imu_T_cam"] # transformation from left camera frame to imu frame 
    
    return t,features,linear_velocity,angular_velocity,K,b,imu_T_cam


def visualize_trajectory_2d(pose,path_name="Unknown",show_ori=False):
    '''
    function to visualize the trajectory in 2D
    Input:
        pose:   4*4*N matrix representing the camera pose, 
                where N is the number of poses, and each
                4*4 matrix is in SE(3)
    '''
    fig,ax = plt.subplots(figsize=(5,5))
    n_pose = pose.shape[2]
    ax.plot(pose[0,3,:],pose[1,3,:],'r-',label=path_name)
    ax.scatter(pose[0,3,0],pose[1,3,0],marker='s',label="start")
    ax.scatter(pose[0,3,-1],pose[1,3,-1],marker='o',label="end")
  
    if show_ori:
        select_ori_index = list(range(0,n_pose,max(int(n_pose/50), 1)))
        yaw_list = []
        
        for i in select_ori_index:
            _,_,yaw = mat2euler(pose[:3,:3,i])
            yaw_list.append(yaw)
    
        dx = np.cos(yaw_list)
        dy = np.sin(yaw_list)
        dx,dy = [dx,dy]/np.sqrt(dx**2+dy**2)
        ax.quiver(pose[0,3,select_ori_index],pose[1,3,select_ori_index],dx,dy,\
            color="b",units="xy",width=1)
    
    ax.set_xlabel('x')
    ax.set_ylabel('y')
    ax.axis('equal')
    ax.grid(False)
    ax.legend()
    plt.show(block=True)

    return fig, ax


def projection(ph):
  '''
  ph = n x 4 = homogeneous point coordinates
  r = n x 4 = ph/ph[...,2] = normalized z axis coordinates
  '''  
  return ph/ph[...,2,None]
  
def projectionJacobian(ph):
  '''
  ph = n x 4 = homogeneous point coordinates
  J = n x 4 x 4 = Jacobian of ph/ph[...,2]
  '''  
  J = np.zeros(ph.shape+(4,))
  iph2 = 1.0/ph[...,2]
  ph2ph2 = ph[...,2]**2
  J[...,0,0], J[...,1,1],J[...,3,3] = iph2,iph2,iph2
  J[...,0,2] = -ph[...,0]/ph2ph2
  J[...,1,2] = -ph[...,1]/ph2ph2
  J[...,3,2] = -ph[...,3]/ph2ph2
  return J


def inversePose(T):
  '''
  @Input:
    T = n x 4 x 4 = n elements of SE(3)
  @Output:
    iT = n x 4 x 4 = inverse of T
  '''
  iT = np.empty_like(T)
  iT[...,0,0], iT[...,0,1], iT[...,0,2] = T[...,0,0], T[...,1,0], T[...,2,0] 
  iT[...,1,0], iT[...,1,1], iT[...,1,2] = T[...,0,1], T[...,1,1], T[...,2,1] 
  iT[...,2,0], iT[...,2,1], iT[...,2,2] = T[...,0,2], T[...,1,2], T[...,2,2]
  iT[...,:3,3] = -np.squeeze(iT[...,:3,:3] @ T[...,:3,3,None])
  iT[...,3,:] = T[...,3,:]
  return iT


def axangle2skew(a):
  '''
  converts an n x 3 axis-angle to an n x 3 x 3 skew symmetric matrix 
  '''
  S = np.empty(a.shape[:-1]+(3,3))
  S[...,0,0].fill(0)
  S[...,0,1] =-a[...,2]
  S[...,0,2] = a[...,1]
  S[...,1,0] = a[...,2]
  S[...,1,1].fill(0)
  S[...,1,2] =-a[...,0]
  S[...,2,0] =-a[...,1]
  S[...,2,1] = a[...,0]
  S[...,2,2].fill(0)
  return S

def axangle2twist(x): #uhat
  '''
  @Input:
    x = n x 6 = n elements of position and axis-angle
  @Output:
    T = n x 4 x 4 = n elements of se(3)
  '''
  T = np.zeros(x.shape[:-1]+(4,4))
  T[...,0,1] =-x[...,5]
  T[...,0,2] = x[...,4]
  T[...,0,3] = x[...,0]
  T[...,1,0] = x[...,5]
  T[...,1,2] =-x[...,3]
  T[...,1,3] = x[...,1]
  T[...,2,0] =-x[...,4]
  T[...,2,1] = x[...,3]
  T[...,2,3] = x[...,2]
  return T

def twist2axangle(T):
  ''' 
  converts an n x 4 x 4 twist (se3) matrix to an n x 6 axis-angle 
  '''
  return T[...,[0,1,2,2,0,1],[3,3,3,1,2,0]]

def axangle2adtwist(x): #u curly hat
  '''
  @Input:
    x = n x 6 = n elements of position and axis-angle
  @Output:
    A = n x 6 x 6 = n elements of ad(se(3))
  '''
  A = np.zeros(x.shape+(6,))
  A[...,0,1] =-x[...,5]
  A[...,0,2] = x[...,4]
  A[...,0,4] =-x[...,2]
  A[...,0,5] = x[...,1]
  
  A[...,1,0] = x[...,5]
  A[...,1,2] =-x[...,3]
  A[...,1,3] = x[...,2]
  A[...,1,5] =-x[...,0]
  
  A[...,2,0] =-x[...,4]
  A[...,2,1] = x[...,3]
  A[...,2,3] =-x[...,1]
  A[...,2,4] = x[...,0]
  
  A[...,3,4] =-x[...,5] 
  A[...,3,5] = x[...,4] 
  A[...,4,3] = x[...,5]
  A[...,4,5] =-x[...,3]   
  A[...,5,3] =-x[...,4]
  A[...,5,4] = x[...,3]
  return A

def twist2pose(T):
  '''
  converts an n x 4 x 4 twist (se3) matrix to an n x 4 x 4 pose (SE3) matrix 
  '''
  rotang = np.sqrt(np.sum(T[...,[2,0,1],[1,2,0]]**2,axis=-1)[...,None,None]) # n x 1
  Tn = np.nan_to_num(T / rotang)
  Tn2 = Tn@Tn
  Tn3 = Tn@Tn2
  eye = np.zeros_like(T)
  eye[...,[0,1,2,3],[0,1,2,3]] = 1.0
  return eye + T + (1.0 - np.cos(rotang))*Tn2 + (rotang - np.sin(rotang))*Tn3
  
def axangle2pose(x):
  '''
  @Input:
    x = n x 6 = n elements of position and axis-angle
  @Output:
    T = n x 4 x 4 = n elements of SE(3)
  '''
  return twist2pose(axangle2twist(x))


def pose2adpose(T):
  '''
  converts an n x 4 x 4 pose (SE3) matrix to an n x 6 x 6 adjoint pose (ad(SE3)) matrix 
  '''
  calT = np.empty(T.shape[:-2]+(6,6))
  calT[...,:3,:3] = T[...,:3,:3]
  calT[...,:3,3:] = axangle2skew(T[...,:3,3]) @ T[...,:3,:3]
  calT[...,3:,:3] = np.zeros(T.shape[:-2]+(3,3))
  calT[...,3:,3:] = T[...,:3,:3]
  return calT
################################################################################################
import numpy as np

# Importing data from dataset 03
t,features_og,linear_velocity,angular_velocity,K,b,imu_T_cam = load_data("C:\Users\prath\Desktop\UCSD Courses\ECE 276A\ECE276A_PR3\data\03.npz")
feature_sampling = range(0, len(features_og[0,:,0]),15)
features = features_og[:, feature_sampling, :] 
time = t[0]

# Printing the data to see the shapes and values
print("time: ",time)
print("\nFeatures: ", features.shape)
print("\nLinear Velocity: ", linear_velocity)
print("\nAngular Velocity: ", angular_velocity)
print("\nLeft Camera Instrinsic Matrix: ",K)
print("\nStereo Camera Baseline: ",b)
print("\nTransformation matrix from camera to IMU: ", imu_T_cam)

# Constructing camera intrinsic matrix (Ks)
fsu = K[0,0]
fsv = K[1,1]
cu = K[0,2]
cv = K[1,2]
K_intrinsic = np.array([[fsu, 0, cu, 0],
                         [0, fsv, cv, 0],
                         [fsu, 0, cu, -fsu*b],
                         [0, fsv, cv, 0]])
print("Camera Intrinsic Matrix: ", K_intrinsic)

# Visualizing Linear and Angular Velocities
plt.figure()
plt.title("Linear Velocity in X direction")
plt.plot(linear_velocity[0])
plt.xlabel("time(t)")
plt.ylabel("Velocity (Vx)")

plt.figure()
plt.title("Linear Velocity in Y direction")
plt.plot(linear_velocity[1])
plt.xlabel("time(t)")
plt.ylabel("Velocity (Vz)")

plt.figure()
plt.title("Linear Velocity in Z direction")
plt.plot(linear_velocity[2])
plt.xlabel("time(t)")
plt.ylabel("Velocity (Vz)")

plt.figure()
plt.title("Angular Velocity in X direction")
plt.plot(angular_velocity[0])
plt.xlabel("time(t)")
plt.ylabel("Angular Velocity (Vx)")

plt.figure()
plt.title("Angular Velocity in Y direction")
plt.plot(angular_velocity[1])
plt.xlabel("time(t)")
plt.ylabel("Angular Velocity (Vz)")

plt.figure()
plt.title("Angular Velocity in Z direction")
plt.plot(angular_velocity[2])
plt.xlabel("time(t)")
plt.ylabel("Angular Velocity (Vz)")
plt.show()

import transforms3d
# Check which landmark is visible
def isVisible(landmarks):
  '''
  INPUT: features at current time step -> (4, 5105)

  OUTPUT: an array with boolean values,
          True -> visible feature
          False -> invisible feature
  '''
  visible = []
  comparison = -1 * np.ones([4, len(landmarks[0, :])])
  difference = comparison - landmarks
  return np.where(np.all(difference, axis=0) == True)

def inverseCam(landmarks):
  z = -K_intrinsic[2,3]/(landmarks[0] - landmarks[2])
  y = (z*(landmarks[1] - K_intrinsic[1,2]))/(K_intrinsic[1,1])
  x = (z*(landmarks[0] - K_intrinsic[0,2]))/(K_intrinsic[0,0])
  return np.array([x, y, z, 1])

def kalmanGain(kalmanGain, n):
  kal_reshape = np.array([np.zeros([3,4])]*n)
  for i in range(0, kalmanGain.shape[0], 3):
    kal_reshape[i//3] = kalmanGain[i:i+3,:]
  return np.hstack(kal_reshape) 

def round_dot(s):
  '''
  INPUT: s ->  4 matrix
  OUTPUT: 4 x 6  matrix
  '''
  I = np.eye(3)
  s_hat = np.array([[0, -s[2], s[1]],
                    [s[2], 0, -s[0]],
                    [-s[1], s[0], 0]])
  zero_row = np.array([[0, 0, 0, 0, 0, 0]])
  return np.concatenate((np.concatenate((I, -s_hat), axis=1), zero_row), axis=0)

def pose2axangle(pose):
  '''
  pose: SE(3)
  '''
  R = pose[:3,:3]
  position = pose[:3,3]
  axis, angles = transforms3d.axangles.mat2axangle(R)
  axangels = axis*angles
  return np.concatenate((position, axangels), axis=0)

def axangletopose(axangle):
  position = np.array([axangle[:3]]).T
  angle = np.linalg.norm(axangle[-3:])
  axangle[-3:] = axangle[-3:]/angle
  R = transforms3d.axangles.axangle2mat(axangle[-3:], angle)
  zero_row = np.array([[0,0,0,1]])
  return np.concatenate((np.concatenate((R, position), axis=1), zero_row), axis=0)

# Initializing the variables
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from scipy import sparse

mean_landmarks = np.ones([4,len(features[0,:,0])])
cov_landmarks = np.array([[0.001*np.eye(3)] * len(features[0,:,0])] * len(features[0,:,0]))

visited = dict()


mu = np.eye(4)
sigma = 0.01*np.eye(6)
last = np.concatenate((np.zeros([3,3]), 0.1*np.eye(3)), axis=1)
W = np.concatenate((np.concatenate((np.eye(3), np.zeros([3,3])),axis=1), last), axis=0)
mean_robot = np.zeros([len(time), 4, 4])
cov_robot = np.zeros([len(time), 6, 6])
mean_robot[0,:] = mu
cov_robot[0,:] = sigma


# EKF Prediction 
for t in tqdm(range(1, len(time))):
# for t in tqdm(range(1, 3)):
  tau = time[t] - time[t-1]
  # Motion model prediction Loop
  u = np.array([linear_velocity[0,t], linear_velocity[1,t], linear_velocity[2,t], angular_velocity[0,t], angular_velocity[1,t], angular_velocity[2,t]])
  u_hat = axangle2twist(u)
  u_curly_hat = axangle2adtwist(u)

  mean_robot[t, :,:] = np.matmul(mean_robot[t-1,:,:],twist2pose(tau*u_hat))# predicted mean of the robot
  cov_robot[t, :, :] = np.matmul(np.matmul(pose2adpose(twist2pose(-tau*u_curly_hat)),cov_robot[t-1,:,:]),np.transpose(pose2adpose(twist2pose(-tau*u_curly_hat)))) + W # predicted covariance matrix of the robot

for t in tqdm(range(1, len(time))):
  # Visual Mapping 
  visible = isVisible(features[:,:,t])
  revisited = []
  for i in visible[0]:
    if features[3,i,t] - features[2,i,t] != 0:
      if i not in visited:
        mean_landmarks[:,i] = mean_robot[t,:,:]@imu_T_cam@inverseCam(features[:,i,t])
        visited[i] = 1
      else:
        # H_matrix = np.array([np.zeros([4,3])]*len(features[0,:,0]))
        revisited.append(i)

        # predicted observations
        z_tilda= K_intrinsic@projection(inversePose(imu_T_cam)@inversePose(mean_robot[t, :, :])@mean_landmarks[:,i])  
        P = np.concatenate((np.eye(3), np.array([[0],[0],[0]])), axis=1)

        # Jacobian of predicted observations
        Jaco = projectionJacobian(inversePose(imu_T_cam)@inversePose(mean_robot[t,:,:])@mean_landmarks[:,i])
        temp = inversePose(imu_T_cam)@inversePose(mean_robot[t,:,:])@np.transpose(P)  
        H_matrix = K_intrinsic@Jaco@temp
        kalman_gain = cov_landmarks[i][i]@H_matrix.T@np.linalg.inv(H_matrix@cov_landmarks[i][i]@H_matrix.T + np.eye(4))
        diff_z = (features[:,i,t] - z_tilda)
        mean_landmarks[:3,i] = mean_landmarks[:3,i] + kalman_gain@diff_z
        cov_landmarks[i][i] = (np.eye(3) - kalman_gain@H_matrix)@cov_landmarks[i][i]
cov_landmarks = np.concatenate(np.concatenate(cov_landmarks, axis=1), axis=1)

# Dead reckoning EKF Prediction IMU Trajectory
visualize_trajectory_2d(np.transpose(mean_robot, (1,2,0)), show_ori=True)
plt.show()

# Map Update
plt.figure(figsize=(8,8))
plt.plot(mean_robot[:,0,3], mean_robot[:,1,3], c='r')
plt.scatter(mean_landmarks[0,:], mean_landmarks[1,:], marker='.')
plt.show()

from scipy import sparse
from tqdm import tqdm

# Extended Kalman Filter Visual SLAM
landmark_cov = np.array([[1*np.eye(3)] * len(features[0,:,0])] * len(features[0,:,0]))
landmark_cov = np.concatenate(np.concatenate(landmark_cov, axis=1), axis=1)
robot_cov = 0.001*np.eye(6)
covariance = np.zeros([3*len(features[0,:,0])+6, 3*len(features[0,:,0])+6])
covariance[:3*len(features[0,:,0]), :3*len(features[0,:,0])] = landmark_cov
covariance[-6:,-6:] = robot_cov
I_cov = np.eye(covariance.shape[0])

robot_mean = np.zeros([len(time), 4, 4])
robot_mean[0,:,:,] = np.eye(4)
landmark_mean = np.zeros([4, len(features[0,:,0])])

visited = dict()

W = np.zeros([6,6])
W[:3,:3] = 0.01*np.eye(3)
W[-3:,-3:] = 0.001*np.eye(3)

for t in tqdm(range(1, len(time))):
# for t in tqdm(range(1, 10)):
  tau = time[t] - time[t-1]
  # Motion model prediction Loop
  u = np.array([linear_velocity[0,t-1], linear_velocity[1,t-1], linear_velocity[2,t-1], angular_velocity[0,t-1], angular_velocity[1,t-1], angular_velocity[2,t-1]])
  u_hat = axangle2twist(u)
  u_curly_hat = axangle2adtwist(u)

  robot_mean[t]= robot_mean[t-1]@twist2pose(tau*u_hat) # predicted mean of the robot
  covariance[-6:,-6:] = twist2pose(-tau*u_curly_hat)@covariance[-6:,-6:]@(twist2pose(-tau*u_curly_hat).T) + W  # predicted covariance matrix of the robot
  
  # SLAM Update
  visible = isVisible(features[:,:,t])
  revisited = []
  z_tilda_f = []
  H_slam = []
  for i in visible[0]:
    if features[3,i,t] - features[2,i,t] != 0:
      if i not in visited:
        landmark_mean[:,i] = robot_mean[t,:,:]@imu_T_cam@inverseCam(features[:,i,t])
        visited[i] = 1
      else:
        landmark_H = np.zeros([4, 3*len(features[0,:,0])])
        revisited.append(i)
        z_tilda_f.append(K_intrinsic@projection(inversePose(imu_T_cam)@inversePose(robot_mean[t, :, :])@landmark_mean[:,i]))  # predicted observations
        P = np.concatenate((np.eye(3), np.array([[0],[0],[0]])), axis=1)
        landmark_H[:,3*i:3*i+3] = K_intrinsic@projectionJacobian(inversePose(imu_T_cam)@inversePose(robot_mean[t,:,:])@landmark_mean[:,i])@inversePose(imu_T_cam)@inversePose(robot_mean[t,:,:])@P.T  # Jacobian of predicted observations        
        # Robot Jacobian
        robot_H = -K_intrinsic@projectionJacobian(inversePose(imu_T_cam)@inversePose(robot_mean[t,:,:])@landmark_mean[:,i])@inversePose(imu_T_cam)@round_dot(inversePose(robot_mean[t,:,:])@landmark_mean[:,i])
        H_slam.append(np.concatenate((landmark_H, robot_H), axis=1))
  if len(revisited) > 0:
    H_slam = np.concatenate(H_slam, axis=0)
    try:
      kalman_gain = covariance@H_slam.T@np.linalg.inv(H_slam@covariance@H_slam.T + 5*np.eye(4*len(revisited)))
    except np.linalg.LinAlgError as err:
      print("Singular error, skipping iteration")
      continue
    z_tilda = np.concatenate(z_tilda_f, axis=0)
    diff_z = np.ravel(features[:,revisited,t], order='F') - z_tilda

    # Split kalman gain
    kalman_gain_robot = kalman_gain[-6:,:]
    kalman_gain_landmark = kalman_gain[:-6,:]
    landmark_mean_reshaped = np.concatenate(landmark_mean[:3,:], axis=0)
    landmark_mean[:3,:] = (landmark_mean_reshaped + kalman_gain_landmark@diff_z).reshape(3, len(features[0,:,0]))
    robot_mean[t,:,:] = robot_mean[t,:,:]@twist2pose(axangle2twist(np.squeeze((kalman_gain_robot@diff_z))))
    covariance = (I_cov - kalman_gain@H_slam)@covariance

# Visual-Inertial SLAM
visualize_trajectory_2d(np.transpose(robot_mean, (1,2,0)), show_ori=True)
plt.show()

# Map from Visual-Inertial SLAM
plt.plot(robot_mean[:,0,3], -robot_mean[:,1,3],  c='r')
plt.scatter(landmark_mean[0,:], -landmark_mean[1,:], marker='.')
plt.show()